# deode_harp_plugin
Plugin interface to run harp point verification for deode extreme weather cases.

# Prerrequisites:
- An installation of harpv02.2 or higher. Instructions can be found here: https://harphub.github.io/harp_training_2024/get-started.html
- Get the official harp scripts for operational use, available in https://github.com/harphub/oper-harp-verif
- To run 

# How to use:
This plugin needs the config.toml file from the deode run that you want to verify as input. Relevant configuration of the verification paths, etc. must be updated in the file harpverify_plugin.toml. 

To create a verification suite from a config.toml and the harpverify_plugin.toml file, create a file -e.g. called configuration- in the Deode-Workflow home directory, with the following content:

> --config-file
> 
>   /path/to/config.toml
> 
>   /path/to/harpverify_plugin.toml
>
Check for the comments in harpverify_plugin.toml to understand how to set each plugin/user specific variable:
```
[general.plugin_registry.plugins]
  harpverify = "/home/sp3c/deode_project/deode_plugins/"
(...)
[scheduler.ecfvars]
  case_prefix = "HARPVERIF_" # Add this to the suite name to not collide with OD case runs.
  ecf_host = "ecflow-gen-sp3c-001" # Hardcode your ecflow server (needed after v0.12.0)
(...)
[submission.harpverify_group.ENV]
  DEODE = "awesome"
  DUSER = "rm6"   # DEODE User: who ran the DEODE case (you or other user)
  HUSER = "sp3c"   # HARP User : who runs the HARP verification (your user)
  HARPSCRIPTS_HOME = "/home/sp3c/deode_project/oper-harp-verif/" # Path to your HARP SCRIPTS installation
  VERIF_HOME= "/ec/res4/hpcperm/sp3c/deode_project/deode_harp_output/" # Root path for HARP results, config files, OBSTABLES and FCTABLES...
  REF_SQLITES="/ec/res4/hpcperm/aut6432/DE_Verification/FCTABLES/" # Where to find sqlites for the reference models
  #OBSTABLES_PATH="/ec/res4/hpcperm/sp3c/deode_project/deode_harp_output/OBSTABLE_MERGED/"
  OBSTABLES_PATH="/ec/res4/hpcperm/aut6432/DE_Verification/OBSTABLES/" # Do not change, these are the official OBSTABLES files for verifications.
  REF_NAME=["GDT_iekm","IFS"] # Names of your reference models
  ECFS_ARCHIVE_RELPATH_HARPOUTPUT="/deode/HARP_VERIF/cases/" # Root to store the HARP results in your permanent archive
  ECFS_ARCHIVE_RELPATH_DEODEOUTPUT="/deode/" #Normally /deode/ for verifyng experiments from generic users, /DE_NWP/deode/ to locate FCTABLES and config files from operational user (aut6432)
  DCMDB_DIR="/home/sp3c/deode_project/dcmdb/" #DCMDB installation. Only used if running the batch script for On-duty runs at once
  DW_DIR="/home/sp3c/deode_project/Deode-Workflow" # Deode-Workflow installation
  RDSS_PATH="/ec/res4/hpcperm/sp3c/deode_project/deode_harp_output/cases/iekm/" # Path to store your HARP results (in subfolders for each case)
  PNGS_PATH="/ec/res4/hpcperm/sp3c/deode_project/deode_harp_output/casesplots/iekm/" # Path to store your HARP figures (in subfolders for each case)
  USE_OPERATIONAL_INDEXING="no" # Whether to use the Operational indexing (use in combination with operational DUSER=aut6432)
  OBS_STEP=3 # Frequecy of observations. Use 1 or 3 hours, tipically
(...)
```
Make sure to create the paths VERIF_HOME, 

The plugin is normally used for verification of the DEODE runs by the on-duty team (DUSER=aut6432), which use a specific way of indexing/archiving runs

If you want to use this plugin to run verifications for one of your own cases, set DUSER=HUSER=your_user and USE_OPERATIONAL_INDEXING=no
## References
It is possible to use more than one reference in the verifications. The reference sqlites should all be available in the path set in REF_SQLITES, and the names of the reference models is set in a list in REF_NAME (both variables set in harpverify_plugin.toml Currently GlobalDT_iekm and IFS are used, for which a daily extraction & interpolation for verification has been set up on the on-duty team user using [extract_dt_plugin](https://github.com/destination-earth-digital-twins/extract_dt_plugin)

Currently the harpverify_plugin.toml is set to use the Global Digital Twin (GDT_iekm) and IFS as references, and the path for the sqlites of these references points to where they are routinely generated by DEODE's operational user (aut6432). They are available for dates after Feb,1, 2025. 
## Scaling units
Finally, for solving some discrepancies with model units of a few variables between these references and the OD runs, a careful setting of scaling of units must be set in the file verification/set_params.R from oper-harp-verif. A copy of the currently operational one can be found at /home/aut6432/DE_Verification/verif_tools/oper-harp-verif/verification/set_params.R
## How to launch your verification suite
NOTE: The verification plugin looks for the information stored in the TOML config file of the case to verify and creates a verification suite plugin using the Deode-Workflow. It is highly recommended that the Deode-Workflow version (tag or commmit) installed in your system is the same as the one used to run the DEODE case. 

After setting your harpverify_plugin.toml correctly, create and launch the verification suite with these commands: 
> poetry shell (or, for more recent DW installs, `poetry env activate` + source the output of the previous command
> 
> deode case ?configuration -o verification_suite.toml
> 
> deode start suite --config-file verification_suite.tom
>
## Automatic scripts

### For single verifications 
launch_from_user.py is a script to run a single verification of a DEODE experiment run by yourself or some other user. Make sure to set ECFS_ARCHIVE_RELPATH_DEODEOUTPUT="/deode/" in harpverify_plugin.toml. The script is run like this:
python3 lauch_from_user.py path/to/harpverify_plugin.toml deode_user experiment_name yyyy mm dd
Where experiment_name is generally the name of the suite of the case run with DW, which is also the name used to store the run in ec:../{deode_user}deode/
If everything went fine, a new suite will appear in your ecflow_ui, named just like the deode case, with a family called "Case_point_verification" and tasks to get the verification files, Verify, and save the files conveniently:

![Screenshot from 2024-10-21 10-59-18](https://github.com/user-attachments/assets/f68f5f10-2488-437b-932d-709bd8914d60)

### For running verifications indexed in dcmdb
In addition, for automatizing verifications run by the on-duty team, an auxiliar script script is available (launch_from_dcmdb.py) to read new runs betweeen two dates from dcmdb,
download the config files and launch all the suites. Make sure that [dcmdb](https://github.com/destination-earth-digital-twins/dcmdb) is installed in your system. The script is run like this:
launch_from_dcmdb.py path/to/harpverify_plugin.toml start_date end_date
